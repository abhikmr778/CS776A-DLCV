{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "package_paths = [\n",
    "    './yolocode/',\n",
    "]\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)\n",
    "    \n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "# add path \n",
    "import colorsys\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import random\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss, yolo_correct_boxes\n",
    "import PIL\n",
    "import torch\n",
    "#!pip install torchmetrics\n",
    "import torchmetrics.detection.map as MeanAveragePrecision\n",
    "import shutil\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from yolo3.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Function for handling data for active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:47:13.019750Z",
     "iopub.status.busy": "2022-04-24T12:47:13.018981Z",
     "iopub.status.idle": "2022-04-24T12:47:13.032880Z",
     "shell.execute_reply": "2022-04-24T12:47:13.032087Z",
     "shell.execute_reply.started": "2022-04-24T12:47:13.019712Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1\n",
    "def make_annotation_txtfile():\n",
    "    '''This func read image_annotations.csv ['id','file_name','height','width','annotations']\n",
    "        and split data into unlable pool and test data\n",
    "    '''\n",
    "    # select nrows from csv file - number of images in dataset for active learning\n",
    "    image_annotations = pd.read_csv(\"./coco_dataset/image_annotations.csv\", nrows=10000)\n",
    "    print('image_annotations',image_annotations.size)\n",
    "    \n",
    "    file = open(\"coco_annotation.txt\",\"a\")\n",
    "    for index, row in image_annotations.iterrows():\n",
    "        a = row[\"annotations\"]\n",
    "        a = re.sub(r\" \", \"\", a)\n",
    "        a = re.sub(r\"],\", \" \", a)\n",
    "        a = re.sub(r\"\\[\", \"\", a)\n",
    "        a = re.sub(r\"\\]\", \"\", a)\n",
    "        if a != \"\":\n",
    "            #file_path = os.path.join(path, row[\"file_name\"])\n",
    "            file.writelines(row[\"file_name\"] + \" \" + a + \"\\n\")\n",
    "            \n",
    "    # split into train and test\n",
    "    file = open(\"coco_annotation.txt\",\"r\")\n",
    "    a = len(file.readlines())\n",
    "    train_num = int(a*0.8) ## Split data into 80 and 20 percent of select data \n",
    "    test_num = a - train_num\n",
    "    file.close()\n",
    "    train_file = open(\"coco_unlabel_pool.txt\", \"a\")\n",
    "    test_file = open(\"coco_test.txt\", \"a\")\n",
    "    with open(\"coco_annotation.txt\",\"r\") as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i <= train_num:\n",
    "                train_file.writelines(line)\n",
    "            else:\n",
    "                test_file.writelines(line)\n",
    "    train_file.close()\n",
    "    test_file.close()\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:47:13.037054Z",
     "iopub.status.busy": "2022-04-24T12:47:13.036538Z",
     "iopub.status.idle": "2022-04-24T12:47:13.044768Z",
     "shell.execute_reply": "2022-04-24T12:47:13.044042Z",
     "shell.execute_reply.started": "2022-04-24T12:47:13.037016Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2\n",
    "# select top n training data\n",
    "def select_train_data(n=100, append=False):\n",
    "    ''' This function select training images from unlabel pool.  '''\n",
    "    temp_file = open(\"temp.txt\",\"a+\")\n",
    "    if append:\n",
    "        train_file = open(\"coco_train.txt\",\"a+\")\n",
    "    else:\n",
    "        train_file = open(\"coco_train.txt\",\"w\")\n",
    "    pool_file = open(\"coco_unlabel_pool.txt\",\"r\")\n",
    "    a  = pool_file.readlines()\n",
    "    \n",
    "    for i in range(n):\n",
    "        train_file.writelines(a[i])\n",
    "    for i in range(n,len(a)):\n",
    "        temp_file.writelines(a[i])\n",
    "\n",
    "    pool_file.close()\n",
    "    temp_file.close() \n",
    "    train_file.close()\n",
    "    if os.path.exists(\"coco_unlabel_pool.txt\"):\n",
    "        os.remove(\"coco_unlabel_pool.txt\")\n",
    "        os.rename('temp.txt', 'coco_unlabel_pool.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:47:13.046771Z",
     "iopub.status.busy": "2022-04-24T12:47:13.046218Z",
     "iopub.status.idle": "2022-04-24T12:47:13.056328Z",
     "shell.execute_reply": "2022-04-24T12:47:13.055488Z",
     "shell.execute_reply.started": "2022-04-24T12:47:13.046735Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3\n",
    "def move_to_train(selected):\n",
    "    temp_file = open(\"temp.txt\",\"a+\")\n",
    "    train_file = open(\"coco_train.txt\",\"a+\")\n",
    "    pool_file = open(\"coco_unlabel_pool.txt\",\"r\")\n",
    "    lines  = pool_file.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        name = line.split()[0]\n",
    "        if name in selected:\n",
    "            train_file.writelines(line)\n",
    "        else:\n",
    "            temp_file.writelines(line)\n",
    "\n",
    "    pool_file.close()\n",
    "    temp_file.close() \n",
    "    train_file.close()\n",
    "    if os.path.exists(\"coco_unlabel_pool.txt\"):\n",
    "        os.remove(\"coco_unlabel_pool.txt\")\n",
    "        os.rename('temp.txt', 'coco_unlabel_pool.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:47:13.058447Z",
     "iopub.status.busy": "2022-04-24T12:47:13.057996Z",
     "iopub.status.idle": "2022-04-24T12:47:13.070554Z",
     "shell.execute_reply": "2022-04-24T12:47:13.069808Z",
     "shell.execute_reply.started": "2022-04-24T12:47:13.058412Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4\n",
    "def get_unlabel_images():\n",
    "    \"\"\" This function return names of images in unlable pool. \"\"\"\n",
    "    pool_file = open(\"coco_unlabel_pool.txt\",\"r\")\n",
    "    lines  = pool_file.readlines()\n",
    "    unlable_images = []\n",
    "    for i in lines:\n",
    "        unlable_images.append(i.split()[0])\n",
    "        \n",
    "    return unlable_images\n",
    "\n",
    "# 5\n",
    "def annotated_images(model_path = \"./yolocode/model_data/yolo_weights.h5\",n = 1000, score_type = 'normal'):\n",
    "    \"\"\" This function make prediction on all the images in unlabel pool and\n",
    "    select training images form unlabel pool based of images scores \"\"\"\n",
    "    # load trained model\n",
    "    model = load_trained_model(input_shape=(416,416), num_classes=80, load_pretrained=True, freeze_body=2,\n",
    "            weights_path=model_path)\n",
    "\n",
    "    unlable_images = get_unlabel_images()\n",
    "    \n",
    "    # calculate score for images\n",
    "    images_score = np.empty((0))\n",
    "    iter = 0\n",
    "    for i in chunks(unlable_images,10):\n",
    "        if iter*10 >= n:\n",
    "            break\n",
    "        if iter%10==0:\n",
    "            print('progress iteration ', iter)\n",
    "        iter = iter + 1\n",
    "        batch = np.empty((0,416,416,3))\n",
    "        for img in  i:\n",
    "            image = read_image(img)\n",
    "            image = preprocess_image(image)\n",
    "            batch = np.append(batch,image,axis=0)\n",
    "        score, prob_score = get_score(batch,model)\n",
    "#         print('prob_score', prob_score)\n",
    "        if score_type == 'prob':\n",
    "            images_score = np.append(images_score,prob_score)\n",
    "        elif score_type == 'normal':\n",
    "            images_score = np.append(images_score,score)\n",
    "    \n",
    "     # select top n images\n",
    "    top_score = (images_score).argsort()[:n]\n",
    "    selected = []\n",
    "    for i in top_score:\n",
    "        selected.append(unlable_images[i])\n",
    "    move_to_train(selected)   \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Training yolo function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:47:13.072525Z",
     "iopub.status.busy": "2022-04-24T12:47:13.072165Z",
     "iopub.status.idle": "2022-04-24T12:47:13.108143Z",
     "shell.execute_reply": "2022-04-24T12:47:13.107481Z",
     "shell.execute_reply.started": "2022-04-24T12:47:13.072490Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data\n",
    "\n",
    "# 1\n",
    "def get_classes(classes_path=\"./yolocode/model_data/coco_classes.txt\"):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "# 2\n",
    "def get_anchors(anchors_path=\"./yolocode/model_data/yolo_anchors.txt\"):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "# 3\n",
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=0,\n",
    "            weights_path='./yolocode/model_data/yolo_weights.h5'):\n",
    "    '''create the training model'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "    ## create list of o/p shape - \n",
    "    ## shape=(None, 13, 13, num_anchors/3 , num_classes+5); \n",
    "    ## shape=(None, 26, 26, num_anchors/3, num_classes+5); \n",
    "    ## shape=(None, 52, 52, num_anchors/3, num_classes+5)\n",
    "    ## +5 for [xmin,ymin,xmax,ymax,class] for all classes and all anchore div into 3 \n",
    "    # load model architecture\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "    \n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "# 4\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "# 5\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
    "\n",
    "# 6\n",
    "def train(batch = 32,epoch = 50,load_pretrained=False,weights_path=\"./logs/000/trained_weights.h5\"):\n",
    "    annotation_path = './coco_train.txt'\n",
    "    log_dir = 'logs/000/'\n",
    "    classes_path = './yolocode/model_data/coco_classes.txt'\n",
    "    anchors_path = './yolocode/model_data/yolo_anchors.txt'\n",
    "    class_names = get_classes(classes_path) ## get list of names\n",
    "    num_classes = len(class_names)\n",
    "    anchors = get_anchors(anchors_path) ## get list of 2d lists\n",
    "  \n",
    "    input_shape = (416,416) # multiple of 32, hw\n",
    "  \n",
    "\n",
    "  \n",
    "    ## LOAD MODEL\n",
    "    model = create_model(input_shape, anchors, num_classes, load_pretrained,weights_path) \n",
    "    \n",
    "  \n",
    "    logging = TensorBoard(log_dir=log_dir)\n",
    "    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "  \n",
    "    # read train annotaion and split 90% train 10% val\n",
    "    val_split = 0.1\n",
    "    with open(annotation_path) as f:\n",
    "        lines = f.readlines()\n",
    "    np.random.seed(10101)\n",
    "    np.random.shuffle(lines)\n",
    "    np.random.seed(None)\n",
    "    num_val = int(len(lines)*val_split)\n",
    "    num_train = len(lines) - num_val\n",
    "  \n",
    "\n",
    "    if True:\n",
    "        for i in range(len(model.layers)):\n",
    "            model.layers[i].trainable = True\n",
    "        model.compile(optimizer=Adam(learning_rate=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "        #print('Unfreeze all of the layers.')\n",
    "        batch_size = batch # note that more GPU memory is required after unfreezing the body\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=epoch,\n",
    "            initial_epoch=0,\n",
    "            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "        model.save_weights(log_dir + 'trained_weights.h5')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Yolo untility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:47:13.109933Z",
     "iopub.status.busy": "2022-04-24T12:47:13.109316Z",
     "iopub.status.idle": "2022-04-24T12:47:13.118039Z",
     "shell.execute_reply": "2022-04-24T12:47:13.117381Z",
     "shell.execute_reply.started": "2022-04-24T12:47:13.109876Z"
    }
   },
   "outputs": [],
   "source": [
    "# preprocess\n",
    "# 1\n",
    "def read_image(image_name):\n",
    "    \n",
    "    path = \"./coco_dataset/images/\"\n",
    "    image = PIL.Image.open(path + image_name)\n",
    "    return image\n",
    "    \n",
    "# 2   \n",
    "def preprocess_image(image):\n",
    "    sq_image = letterbox_image(image, (416,416))\n",
    "    image_data = np.array(sq_image)\n",
    "    image_data = image_data/255.\n",
    "    image_data = np.expand_dims(image_data, 0) # (1, 416, 416, 3)\n",
    "    return image_data\n",
    "\n",
    "# 3\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:47:13.120035Z",
     "iopub.status.busy": "2022-04-24T12:47:13.119515Z",
     "iopub.status.idle": "2022-04-24T12:47:13.143874Z",
     "shell.execute_reply": "2022-04-24T12:47:13.143213Z",
     "shell.execute_reply.started": "2022-04-24T12:47:13.119998Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4\n",
    "def load_trained_model(input_shape=(416,416), num_classes=80, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/yolo_weights.h5'):\n",
    "    '''create the training model'''\n",
    "    #anchors_path = '../input/yolocode/model_data/yolo_anchors.txt'\n",
    "    \n",
    "    anchors = get_anchors()\n",
    "    \n",
    "    \n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "    ## create list of o/p shape - \n",
    "    ## shape=(None, 13, 13, num_anchors/3 , num_classes+5); \n",
    "    ## shape=(None, 26, 26, num_anchors/3, num_classes+5); \n",
    "    ## shape=(None, 52, 52, num_anchors/3, num_classes+5)\n",
    "    ## +5 for [xmin,ymin,xmax,ymax,class] for all classes and all anchore div into 3 \n",
    "\n",
    "    # load model architecture\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    # LOAD pretarin model weights\n",
    "    \n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    return model_body\n",
    "\n",
    "# 5\n",
    "def get_score(image,yolo_model):\n",
    "    \"\"\" This function calculate score of the image \"\"\"\n",
    "    # get data\n",
    "    anchors = get_anchors()\n",
    "    class_names = get_classes()\n",
    "    num_anchors = len(anchors)\n",
    "    num_classes = len(class_names)\n",
    "     \n",
    "    yolo_outputs = yolo_model.predict(image)\n",
    "    # (1, 13, 13, 255) \n",
    "    # (1, 26, 26, 255)\n",
    "    # (1, 52, 52, 255)\n",
    "    \n",
    "    \n",
    "    score_batch = np.zeros((image.shape[0])) # ((None,416,416,3))\n",
    "    al_ep_score = np.zeros((image.shape[0]))\n",
    "    for i in range(len(image)):\n",
    "        _output = [ np.expand_dims(yolo_outputs[0][i],0), np.expand_dims(yolo_outputs[1][i],0), np.expand_dims(yolo_outputs[2][i],0) ]\n",
    "        out_boxes, out_scores, out_classes, uncert_all_classes = yolo_eval(_output,anchors,num_classes,\n",
    "                                                   [416,416],\n",
    "                                                   max_boxes=20,score_threshold=.6,\n",
    "                                                   iou_threshold=.5)\n",
    "        \n",
    "        # calculating aleatoric and epistemic uncertainities for every image\n",
    "#         print('out_classes', out_classes)\n",
    "#         print('out_scores', out_scores)\n",
    "#         print('uncert', uncert_all_classes)\n",
    "        u_al = 0\n",
    "        u_ep = 0\n",
    "        normalized_scores = out_scores\n",
    "        if len(out_scores)>0:\n",
    "            normalized_scores = out_scores/np.max(out_scores)\n",
    "            normalized_scores = normalized_scores.numpy()\n",
    "        out_classes = out_classes.numpy()\n",
    "#         print('normalized', normalized_scores)\n",
    "        sum_pi_mu = 0\n",
    "        for c,s in zip(out_classes,normalized_scores):\n",
    "            for b in uncert_all_classes[c]:\n",
    "                for u in b:\n",
    "#                     print('s', s, 'mu', u[0])\n",
    "                    sum_pi_mu += np.log(s*tf.clip_by_value(u[0], clip_value_min=0.0, clip_value_max=tf.float32.max)+1)\n",
    "        \n",
    "        for c,s in zip(out_classes,normalized_scores):\n",
    "            for b in uncert_all_classes[c]:\n",
    "                for u in b:\n",
    "                    mu = u[0]\n",
    "                    var = u[1]\n",
    "#                     print('mu', mu, 'var', var)\n",
    "                    u_al += np.log(s*var+1)\n",
    "                    u_ep += np.log(s*np.abs(mu - sum_pi_mu)**2+1)\n",
    "        \n",
    "        \n",
    "        score_batch[i] = np.average(out_scores)   \n",
    "#         print('u_al', u_al, 'u_ep', u_ep)\n",
    "        al_ep_score[i] = u_al + u_ep\n",
    "    return score_batch, al_ep_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:47:13.120035Z",
     "iopub.status.busy": "2022-04-24T12:47:13.119515Z",
     "iopub.status.idle": "2022-04-24T12:47:13.143874Z",
     "shell.execute_reply": "2022-04-24T12:47:13.143213Z",
     "shell.execute_reply.started": "2022-04-24T12:47:13.119998Z"
    }
   },
   "outputs": [],
   "source": [
    "#6\n",
    "def yolo_predict(image, model_path = \"./yolocode/model_data/yolo_weights.h5\"):\n",
    "    # preprocess image\n",
    "    image_data = preprocess_image(image) # (1, 416, 416, 3)\n",
    "    \n",
    "    # get data\n",
    "    anchors = get_anchors()\n",
    "    class_names = get_classes()\n",
    "    num_anchors = len(anchors)\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    # load model\n",
    "    yolo_model = load_trained_model(input_shape=(416,416), num_classes=num_classes, load_pretrained=True,freeze_body=2,weights_path=model_path)\n",
    "    #yolo_model = load_model(model_path, compile=False)\n",
    "    \n",
    "    yolo_outputs = yolo_model.predict(image_data)\n",
    "    # (1, 13, 13, 255)\n",
    "    # (1, 26, 26, 255)\n",
    "    # (1, 52, 52, 255)\n",
    "    \n",
    "    out_boxes, out_scores, out_classes, _ = yolo_eval(yolo_outputs,anchors,num_classes,[image.size[1],image.size[0]],max_boxes=20,score_threshold=.6,iou_threshold=.5)\n",
    "    image = draw_boxes(out_boxes, out_scores, out_classes, image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 7\n",
    "def get_uncert_score(boxes, scores, max_output_size, iou_threshold=0.5, score_threshold=float('-inf'), name=None):\n",
    "    \"\"\" This function calculate uncertanty score before applying nms \"\"\"\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    scores = scores\n",
    "    order = tf.argsort(scores)\n",
    "    areas = (x2-x1)*(y2-y1)\n",
    "    keep = []\n",
    "    nms_idx = []\n",
    "    uncert = []\n",
    "    while len(order) > 0:\n",
    "        idx = order[-1]\n",
    "        \n",
    "        keep.append(boxes[idx].numpy())\n",
    "        nms_idx.append(idx.numpy())\n",
    "        order = order[:-1]\n",
    "\n",
    "        xx1 = tf.gather(x1,indices=order,axis=0)\n",
    "        xx2 = tf.gather(x2,indices=order,axis=0)\n",
    "        yy1 = tf.gather(y1,indices=order,axis=0)\n",
    "        yy2 = tf.gather(y2,indices=order,axis=0)\n",
    "        \n",
    "        xx1 = tf.math.maximum(xx1,x1[idx])\n",
    "        yy1 = tf.math.maximum(yy1,y1[idx])\n",
    "        xx2 = tf.math.minimum(xx2,x2[idx])\n",
    "        yy2 = tf.math.minimum(yy2,y2[idx])\n",
    "        \n",
    "        w = xx2 - xx1\n",
    "        h = yy2 - yy1\n",
    "        \n",
    "        w = tf.clip_by_value(w, clip_value_min=0.0, clip_value_max = tf.float32.max)\n",
    "        h = tf.clip_by_value(h, clip_value_min=0.0, clip_value_max = tf.float32.max)\n",
    "        \n",
    "        inter = w*h\n",
    "        \n",
    "        rem_areas = tf.gather(areas,indices=order,axis=0)\n",
    "        \n",
    "        union = (rem_areas - inter) + areas[idx]\n",
    "        \n",
    "        IoU = inter/union\n",
    "        \n",
    "#         mask = IoU < iou_threshold\n",
    "#         order = order[mask]\n",
    "        mask = IoU < 0.5\n",
    "        inv_mask = IoU > 0.5\n",
    "        \n",
    "        cluster_idx = order[inv_mask]\n",
    "        cluster_idx = list(cluster_idx.numpy())\n",
    "        cluster_idx.append(idx.numpy())\n",
    "#         tf.stack([cluster_idx.numpy(), [idx.numpy()]], axis=0)\n",
    "        order = order[mask]\n",
    "        \n",
    "        \n",
    "        \n",
    "        x1_ = [x1[i].numpy() for i in cluster_idx]\n",
    "        y1_ = [y1[i].numpy() for i in cluster_idx]\n",
    "        x2_ = [x2[i].numpy() for i in cluster_idx]\n",
    "        y2_ = [y2[i].numpy() for i in cluster_idx]\n",
    "        \n",
    "        x1_ = np.array(x1_)\n",
    "        y1_ = np.array(y1_)\n",
    "        x2_ = np.array(x2_)\n",
    "        y2_ = np.array(y2_)\n",
    "        \n",
    "        x1_mu = x1_.mean() \n",
    "        y1_mu = y1_.mean()\n",
    "        x2_mu = x2_.mean()\n",
    "        y2_mu = y2_.mean()\n",
    "        \n",
    "        x1_var = x1_.var() \n",
    "        y1_var = y1_.var()\n",
    "        x2_var = x2_.var()\n",
    "        y2_var = y2_.var()\n",
    "        \n",
    "        \n",
    "        uncert.append([[x1_mu, x1_var], [y1_mu, y1_var], [x2_mu, x2_var], [y2_mu, y2_var]])\n",
    "    \n",
    "    return tf.convert_to_tensor(keep,dtype=tf.float32), tf.convert_to_tensor(nms_idx,dtype=tf.int32), uncert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:47:13.182213Z",
     "iopub.status.busy": "2022-04-24T12:47:13.181615Z",
     "iopub.status.idle": "2022-04-24T12:47:13.217880Z",
     "shell.execute_reply": "2022-04-24T12:47:13.217170Z",
     "shell.execute_reply.started": "2022-04-24T12:47:13.182179Z"
    }
   },
   "outputs": [],
   "source": [
    "# 8\n",
    "def yolo_eval(yolo_outputs,\n",
    "              anchors,\n",
    "              num_classes,\n",
    "              image_shape,\n",
    "              max_boxes=20,\n",
    "              score_threshold=.6,\n",
    "              iou_threshold=.5):\n",
    "    \"\"\"Evaluate YOLO model on given input and return filtered boxes.\"\"\"\n",
    "    num_layers = len(yolo_outputs)\n",
    "       \n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]] # default setting\n",
    "    input_shape = K.shape(yolo_outputs[0])[1:3] * 32\n",
    "    boxes = []\n",
    "    box_scores = []\n",
    "    for l in range(num_layers):\n",
    "        _boxes, _box_scores = yolo_boxes_and_scores(yolo_outputs[l],\n",
    "            anchors[anchor_mask[l]], num_classes, input_shape, image_shape)\n",
    "        boxes.append(_boxes)\n",
    "        box_scores.append(_box_scores)\n",
    "    boxes = K.concatenate(boxes, axis=0)\n",
    "    box_scores = K.concatenate(box_scores, axis=0)\n",
    "\n",
    "    mask = box_scores >= score_threshold\n",
    "    max_boxes_tensor = K.constant(max_boxes, dtype='int32')\n",
    "    boxes_ = []\n",
    "    scores_ = []\n",
    "    classes_ = []\n",
    "    uncert_all_classes = []\n",
    "    for c in range(num_classes):\n",
    "        # TODO: use keras backend instead of tf.\n",
    "        class_boxes = tf.boolean_mask(boxes, mask[:, c])\n",
    "        class_box_scores = tf.boolean_mask(box_scores[:, c], mask[:, c])\n",
    "        nms_index = tf.image.non_max_suppression(\n",
    "            class_boxes, class_box_scores, max_boxes_tensor, iou_threshold=iou_threshold)\n",
    "        mynms_out, mynms_index, uncert = get_uncert_score(class_boxes, class_box_scores, max_boxes_tensor, iou_threshold=iou_threshold)\n",
    "        uncert_all_classes.append(uncert)\n",
    "        class_boxes = K.gather(class_boxes, nms_index)\n",
    "        class_box_scores = K.gather(class_box_scores, nms_index)\n",
    "        classes = K.ones_like(class_box_scores, 'int32') * c\n",
    "        boxes_.append(class_boxes)\n",
    "        scores_.append(class_box_scores)\n",
    "        classes_.append(classes)\n",
    "    boxes_ = K.concatenate(boxes_, axis=0)\n",
    "    scores_ = K.concatenate(scores_, axis=0)\n",
    "    classes_ = K.concatenate(classes_, axis=0)\n",
    "\n",
    "    return boxes_, scores_, classes_, uncert_all_classes\n",
    "\n",
    "# 9\n",
    "def yolo_boxes_and_scores(feats, anchors, num_classes, input_shape, image_shape):\n",
    "    '''Process Conv layer output'''\n",
    "    box_xy, box_wh, box_confidence, box_class_probs = yolo_head(feats,\n",
    "        anchors, num_classes, input_shape)    \n",
    "    boxes = yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape)\n",
    "    boxes = K.reshape(boxes, [-1, 4])\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    box_scores = K.reshape(box_scores, [-1, num_classes])\n",
    "    return boxes, box_scores\n",
    "\n",
    "# 10\n",
    "def yolo_head(feats, anchors, num_classes, input_shape, calc_loss=False):\n",
    "    \"\"\"Convert final layer features to bounding box parameters.\"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors, 2])\n",
    "\n",
    "    grid_shape = K.shape(feats)[1:3] # height, width\n",
    "    grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),\n",
    "        [1, grid_shape[1], 1, 1])\n",
    "    grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),\n",
    "        [grid_shape[0], 1, 1, 1])\n",
    "    grid = K.concatenate([grid_x, grid_y])\n",
    "    grid = K.cast(grid, np.float32)\n",
    "\n",
    "    feats = K.reshape(\n",
    "        feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n",
    "    \n",
    "    \n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    box_xy = (K.sigmoid(feats[..., :2]) + grid) / K.cast(grid_shape[::-1], K.dtype(feats))\n",
    "    box_wh = K.exp(feats[..., 2:4]) * anchors_tensor / K.cast(input_shape[::-1], K.dtype(feats))\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_class_probs = K.sigmoid(feats[..., 5:])\n",
    "\n",
    "    if calc_loss == True:\n",
    "        return grid, feats, box_xy, box_wh\n",
    "    \n",
    "    return box_xy, box_wh, box_confidence, box_class_probs\n",
    "\n",
    "# 11\n",
    "def draw_boxes(out_boxes, out_scores, out_classes, image):\n",
    "    class_names = get_classes()\n",
    "    font = ImageFont.load_default()\n",
    "    thickness = (image.size[0] + image.size[1]) // 300\n",
    "    colors = get_colors_for_classes(len(class_names))\n",
    "    # out_classes\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "        predicted_class = class_names[c]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "    \n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        label_size = draw.textsize(label, font)\n",
    "    \n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "        print(label, (left, top), (right, bottom))\n",
    "    \n",
    "        if top - label_size[1] >= 0:\n",
    "            text_origin = np.array([left, top - label_size[1]])\n",
    "        else:\n",
    "            text_origin = np.array([left, top + 1])\n",
    "    \n",
    "        \n",
    "        for i in range(thickness):\n",
    "            draw.rectangle(\n",
    "                [left + i, top + i, right - i, bottom - i],\n",
    "                outline=colors[c])\n",
    "        draw.rectangle(\n",
    "            [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "            fill=colors[c])\n",
    "        draw.text(list(text_origin), label, fill=(0, 0, 0), font=font)\n",
    "        del draw\n",
    "    \n",
    "    return image\n",
    "\n",
    "# 12\n",
    "def get_colors_for_classes(num_classes):\n",
    "    \"\"\"Return list of random colors for number of classes given.\"\"\"\n",
    "    # Use previously generated colors if num_classes is the same.\n",
    "    if (hasattr(get_colors_for_classes, \"colors\") and\n",
    "            len(get_colors_for_classes.colors) == num_classes):\n",
    "        return get_colors_for_classes.colors\n",
    "\n",
    "    hsv_tuples = [(x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(\n",
    "        map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "            colors))\n",
    "    random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "    random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "    random.seed(None)  # Reset seed to default.\n",
    "    get_colors_for_classes.colors = colors  # Save colors for future calls.\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### yolo test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:47:13.221289Z",
     "iopub.status.busy": "2022-04-24T12:47:13.220778Z",
     "iopub.status.idle": "2022-04-24T12:47:13.245130Z",
     "shell.execute_reply": "2022-04-24T12:47:13.244509Z",
     "shell.execute_reply.started": "2022-04-24T12:47:13.221252Z"
    }
   },
   "outputs": [],
   "source": [
    "# 13\n",
    "def get_test():\n",
    "    # list images names And its annotation\n",
    "    test_file = open(\"./coco_test.txt\",\"r\")\n",
    "    lines  = test_file.readlines()\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in lines:\n",
    "        images.append(i.split()[0])\n",
    "        labels.append(i.split()[1:])\n",
    "    return images, labels\n",
    "\n",
    "#14\n",
    "def yolo_test(model_path=\"./yolocode/model_data/yolo_weights.h5\"):\n",
    "    \"\"\" This function read images from test set and make prediction it return ground truth and prediction \"\"\"\n",
    "    TESTED = 5000\n",
    "    \n",
    "    test_images, test_labels = get_test()\n",
    "    # ['5,35,475,379,48', '0,287,342,426,lable']\n",
    "    # load model\n",
    "    yolo_model = load_model(model_path, compile=False)\n",
    "    \n",
    "    # get data\n",
    "    anchors = get_anchors()\n",
    "    class_names = get_classes()\n",
    "    num_anchors = len(anchors)\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    ann = []\n",
    "    det = []\n",
    "    for i in range(len(test_images)):\n",
    "        print(\"Testing : \" + str(i) + \"/\" + str(TESTED), end=\"\\r\")\n",
    "        img = test_images[i]\n",
    "        labels = test_labels[i]\n",
    "        \n",
    "        # read image\n",
    "        image = read_image(img)\n",
    "\n",
    "        \n",
    "        ### Create annotation formate\n",
    "        for k in range(len(labels)):            \n",
    "            labels[k] = labels[k].split(\",\")\n",
    "            labels[k] = [int(j) for j in labels[k]] # create int list\n",
    "        labels = np.array(labels)\n",
    "        labels[:, [2, 1]] = labels[:, [1, 2]]\n",
    "        labels = np.insert(labels, 0,0, axis=1)\n",
    "        \n",
    "        labels = labels[:, [0,5,1,2,3,4]]\n",
    "        \n",
    "        df = pd.DataFrame(labels,columns =['name','class','xmin','xmax','ymin','ymax'])\n",
    "        df = df.replace({'name': 0}, img)\n",
    "        df = df.replace({\"class\": dict(zip(range(len(class_names)), class_names))})\n",
    "        df['xmin'] = df['xmin'].div(image.size[0])\n",
    "        df['xmax'] = df['xmax'].div(image.size[0])\n",
    "        df['ymin'] = df['ymin'].div(image.size[1])\n",
    "        df['ymax'] = df['ymax'].div(image.size[1])\n",
    "        ann.append(df)\n",
    "        # preprocess image\n",
    "        image_data = preprocess_image(image) # (1, 416, 416, 3)\n",
    "        \n",
    "        yolo_outputs = yolo_model.predict(image_data)\n",
    "        # (1, 13, 13, 255)     # (1, 26, 26, 255)      # (1, 52, 52, 255)\n",
    "        \n",
    "        out_boxes, out_scores, out_classes, _ = yolo_eval(yolo_outputs,anchors,num_classes,[image.size[1],image.size[0]],max_boxes=20,score_threshold=.6,iou_threshold=.5)\n",
    "        # TODO: using labels and (out_boxes, out_classes) calcuate map\n",
    "        \n",
    "        # create output labels formate\n",
    "        out_boxes = np.array(out_boxes)\n",
    "        # correct boxes\n",
    "        for j in range(len(out_boxes)):\n",
    "            out_boxes[j][0] =  max(0, out_boxes[j][0])\n",
    "            out_boxes[j][1] =  max(0, out_boxes[j][1])\n",
    "            out_boxes[j][2] =  min(image.size[1], out_boxes[j][2])\n",
    "            out_boxes[j][3] =  min(image.size[0], out_boxes[j][3])\n",
    "        out_boxes[:, [2, 1]] = out_boxes[:, [1, 2]] # swap xmin,xmax,ymin,ymax\n",
    "        out_boxes = np.insert(out_boxes, 0,out_scores, axis=1) # add score\n",
    "        out_boxes = np.insert(out_boxes, 0,out_classes, axis=1) # add class\n",
    "        out_boxes = np.insert(out_boxes, 0,0, axis=1) # add 0 for img name\n",
    "        \n",
    "        df2 = pd.DataFrame(out_boxes,columns =['name','class','score','xmin','xmax','ymin','ymax'])\n",
    "        df2 = df2.replace({'name': 0}, img)\n",
    "        df2 = df2.replace({\"class\": dict(zip(range(len(class_names)), class_names))})\n",
    "        df2['xmin'] = df2['xmin'].div(image.size[0])\n",
    "        df2['xmax'] = df2['xmax'].div(image.size[0])\n",
    "        df2['ymin'] = df2['ymin'].div(image.size[1])\n",
    "        df2['ymax'] = df2['ymax'].div(image.size[1])\n",
    "        det.append(df2)\n",
    "        if i == TESTED:\n",
    "            break\n",
    "    ann = pd.concat(ann)\n",
    "    det = pd.concat(det)\n",
    "    return ann, det\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5. mAP Score functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:47:16.232569Z",
     "iopub.status.busy": "2022-04-24T12:47:16.232000Z",
     "iopub.status.idle": "2022-04-24T12:47:16.248321Z",
     "shell.execute_reply": "2022-04-24T12:47:16.247540Z",
     "shell.execute_reply.started": "2022-04-24T12:47:16.232533Z"
    }
   },
   "outputs": [],
   "source": [
    "def getDataForMap(model_path):\n",
    "    \"\"\" This function calculate mAP for test data given model path \"\"\"\n",
    "    test_images, test_labels = get_test()\n",
    "    \n",
    "    # get targets\n",
    "    target = []\n",
    "    preds = []\n",
    "    \n",
    "    # get data\n",
    "    anchors = get_anchors()\n",
    "    class_names = get_classes()\n",
    "    num_anchors = len(anchors)\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    # load model\n",
    "    yolo_model = load_trained_model(input_shape=(416,416), num_classes=num_classes, load_pretrained=True,freeze_body=2,weights_path=model_path)\n",
    "    #yolo_model = load_model(model_path, compile=False)\n",
    "    iii = 0\n",
    "    \n",
    "    \n",
    "    print(\"total test:\" , len(test_labels))\n",
    "    for a in test_labels:\n",
    "        iii = iii +1\n",
    "        \n",
    "#         if iii == 100:\n",
    "#             break\n",
    "        print(iii)\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for b in a:\n",
    "            c = b.split(\",\")\n",
    "            c = [int(i) for i in c]\n",
    "            \n",
    "            #bbox = [c[0],c[1],c[0]+c[2],c[1]+c[3]]\n",
    "            \n",
    "            boxes.append(c[:-1])\n",
    "            labels.append(c[-1])\n",
    "              \n",
    "        #labels = [i-1 for i in labels]\n",
    "        target.append(\n",
    "        dict(\n",
    "            boxes=torch.tensor(boxes),\n",
    "            labels=torch.tensor(labels),\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    iii = 0\n",
    "    print(len(test_images))\n",
    "    for names in test_images:\n",
    "        iii = iii +1\n",
    "        \n",
    "#         if iii == 100:\n",
    "#             break\n",
    "        print(iii)\n",
    "        image = read_image(names)\n",
    "        image_data = preprocess_image(image) # (1, 416, 416, 3)\n",
    "        \n",
    "        \n",
    "        \n",
    "        yolo_outputs = yolo_model.predict(image_data)\n",
    "        \n",
    "        out_boxes, out_scores, out_classes, _ = yolo_eval(yolo_outputs,anchors,num_classes,[image.size[1],image.size[0]],max_boxes=20,score_threshold=.6,iou_threshold=.5)\n",
    "        \n",
    "        out_boxes =  out_boxes.numpy()\n",
    "        \n",
    "        for i in range(len(out_boxes)):\n",
    "            out_boxes[i][0] = max(0, np.floor(out_boxes[i][0] + 0.5).astype('int32'))\n",
    "            out_boxes[i][1] = max(0, np.floor(out_boxes[i][1] + 0.5).astype('int32'))\n",
    "            out_boxes[i][2] = min(image.size[1], np.floor(out_boxes[i][2] + 0.5).astype('int32'))\n",
    "            out_boxes[i][3] = min(image.size[0], np.floor(out_boxes[i][3] + 0.5).astype('int32'))\n",
    "        \n",
    "        out_boxes = out_boxes[:, [1, 0, 3, 2]]\n",
    "        \n",
    "        \n",
    "        preds.append(dict(\n",
    "            boxes=torch.tensor(out_boxes),\n",
    "            scores=torch.tensor(out_scores.numpy()),\n",
    "            labels=torch.tensor(out_classes.numpy()),\n",
    "            ))\n",
    "    \n",
    "        \n",
    "    return preds, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6. Active learning loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Setting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-04-24T12:47:13.258306Z",
     "iopub.status.busy": "2022-04-24T12:47:13.258002Z",
     "iopub.status.idle": "2022-04-24T12:47:16.194886Z",
     "shell.execute_reply": "2022-04-24T12:47:16.194155Z",
     "shell.execute_reply.started": "2022-04-24T12:47:13.258269Z"
    }
   },
   "outputs": [],
   "source": [
    "## Setting data\n",
    "## making annotation files\n",
    "make_annotation_txtfile()\n",
    "select_train_data(100) # select  init data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:47:16.270466Z",
     "iopub.status.busy": "2022-04-24T12:47:16.269784Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "log_dir = 'logs/000/'\n",
    "\n",
    "# train intial model\n",
    "train(batch = BATCH_SIZE,epoch = EPOCHS, load_pretrained=True,weights_path=\"./yolocode/model_data/yolo_weights.h5\")\n",
    "AL_map = []\n",
    "\n",
    "# active learning loop\n",
    "for i in range(100):\n",
    "    # select new images for training \n",
    "    print('Active Learning Iteration ',i)\n",
    "    ## change score_type to select scoring function normal / prob (for uncertanty based scoring function)\n",
    "    ## annotate image based on previously trained model\n",
    "    annotated_images(model_path = \"./logs/000/trained_weights.h5\",n=30,score_type = 'normal')\n",
    "    \n",
    "    # train new model with new training images selected\n",
    "    train(batch = BATCH_SIZE,epoch = EPOCHS,load_pretrained=True,weights_path=\"./yolocode/model_data/yolo_weights.h5\" )\n",
    "    shutil.copyfile(log_dir + \"/trained_weights.h5\", log_dir + \"/trained_weights_\"+str(i)+\".h5\")\n",
    "    \n",
    "    # calculate mAP score\n",
    "    preds, target = getDataForMap(log_dir + \"/trained_weights_\"+str(i)+\".h5\")\n",
    "    metric = MeanAveragePrecision.MAP()\n",
    "    metric.update(preds, target)\n",
    "    pprint(metric.compute())\n",
    "    AL_map.append(metric.compute())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
